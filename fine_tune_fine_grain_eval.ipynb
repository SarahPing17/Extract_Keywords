{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust the function to allow for more lenient matching, particularly for substrings or partial words\n",
    "def find_partial_matches(predicted, actual):\n",
    "    set1 = set(predicted)\n",
    "    set2 = set(actual)\n",
    "    common_words = set()\n",
    "    common_words = set1.intersection(set2)\n",
    "    for pred_label in predicted:\n",
    "        for act_label in actual:\n",
    "            # Check if either label contains the other as a substring (case-insensitive)\n",
    "            if pred_label in act_label or act_label in pred_label:\n",
    "                common_words.add((pred_label))\n",
    "    return common_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_accuracy(directory):\n",
    "    \"\"\"\n",
    "    Read JSON files from a directory and extract the contents.\n",
    "\n",
    "    :param directory: Directory from which the files will be read.\n",
    "    :return: A list of dictionaries containing the contents of each file.\n",
    "    \"\"\"\n",
    "    file_contents = []\n",
    "    i = 0\n",
    "    prevsum = 0\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith('.json'):\n",
    "            i = i+1\n",
    "            file_path = os.path.join(directory, filename)\n",
    "            with open(file_path, 'r') as file:\n",
    "                data = json.load(file)\n",
    "            keywords_set = re.split(r'\\s*[;,]\\s*', data['keyword'])\n",
    "            keywords_count = len(keywords_set)\n",
    "            model_result_set = re.split(r'\\s*[;,]\\s*', data['model_result'])\n",
    "            model_result_count = len(model_result_set)\n",
    "            partial_matches = find_partial_matches(model_result_set, keywords_set)\n",
    "            partial_matches_count = len(partial_matches)\n",
    "            curpart = partial_matches_count/(keywords_count+model_result_count-partial_matches_count)\n",
    "            if curpart < 0 or partial_matches_count<0:\n",
    "                print(filename, keywords_count, model_result_count, partial_matches_count)\n",
    "            prevsum += curpart\n",
    "    accuracy = 1/i * prevsum\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38670608670608675"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate Accuracy\n",
    "dir = '/Users/yihanping/Documents/gatech/Research/ProcessPDF/pdf_downloads/test_dataset_large/CS/json'\n",
    "acc =  cal_accuracy(dir)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recall\n",
    "def cal_recall(directory):\n",
    "    \"\"\"\n",
    "    Read JSON files from a directory and extract the contents.\n",
    "\n",
    "    :param directory: Directory from which the files will be read.\n",
    "    :return: A list of dictionaries containing the contents of each file.\n",
    "    \"\"\"\n",
    "    file_contents = []\n",
    "    i = 0\n",
    "    prevsum = 0\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith('.json'):\n",
    "            i = i+1\n",
    "            file_path = os.path.join(directory, filename)\n",
    "            with open(file_path, 'r') as file:\n",
    "                data = json.load(file)\n",
    "            keywords_set = re.split(r'\\s*[;,]\\s*', data['keyword'])\n",
    "            keywords_count = len(keywords_set)\n",
    "            model_result_set = re.split(r'\\s*[;,]\\s*', data['model_result'])\n",
    "            model_result_count = len(model_result_set)\n",
    "            partial_matches = find_partial_matches(model_result_set, keywords_set)\n",
    "            partial_matches_count = len(partial_matches)\n",
    "            curpart = partial_matches_count/keywords_count\n",
    "            if curpart < 0 or partial_matches_count<0:\n",
    "                print(filename, keywords_count, model_result_count, partial_matches_count)\n",
    "            prevsum += curpart\n",
    "    accuracy = 1/i * prevsum\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48482605982605986"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate Accuracy\n",
    "dir = '/Users/yihanping/Documents/gatech/Research/ProcessPDF/pdf_downloads/test_dataset_large/CS/json'\n",
    "recall =  cal_recall(dir)\n",
    "recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision\n",
    "def cal_precision(directory):\n",
    "    \"\"\"\n",
    "    Read JSON files from a directory and extract the contents.\n",
    "\n",
    "    :param directory: Directory from which the files will be read.\n",
    "    :return: A list of dictionaries containing the contents of each file.\n",
    "    \"\"\"\n",
    "    file_contents = []\n",
    "    i = 0\n",
    "    prevsum = 0\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith('.json'):\n",
    "            i = i+1\n",
    "            file_path = os.path.join(directory, filename)\n",
    "            with open(file_path, 'r') as file:\n",
    "                data = json.load(file)\n",
    "            keywords_set = re.split(r'\\s*[;,]\\s*', data['keyword'])\n",
    "            keywords_count = len(keywords_set)\n",
    "            model_result_set = re.split(r'\\s*[;,]\\s*', data['model_result'])\n",
    "            model_result_count = len(model_result_set)\n",
    "            partial_matches = find_partial_matches(model_result_set, keywords_set)\n",
    "            partial_matches_count = len(partial_matches)\n",
    "            curpart = partial_matches_count/model_result_count\n",
    "            if curpart < 0 or partial_matches_count<0:\n",
    "                print(filename, keywords_count, model_result_count, partial_matches_count)\n",
    "            prevsum += curpart\n",
    "    accuracy = 1/i * prevsum\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4245495495495496"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate Precision\n",
    "dir = '/Users/yihanping/Documents/gatech/Research/ProcessPDF/pdf_downloads/test_dataset_large/CS/json'\n",
    "precision =  cal_precision(dir)\n",
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F1\n",
    "def cal_F1(directory):\n",
    "    \"\"\"\n",
    "    Read JSON files from a directory and extract the contents.\n",
    "\n",
    "    :param directory: Directory from which the files will be read.\n",
    "    :return: A list of dictionaries containing the contents of each file.\n",
    "    \"\"\"\n",
    "    file_contents = []\n",
    "    i = 0\n",
    "    prevsum = 0\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith('.json'):\n",
    "            i = i+1\n",
    "            file_path = os.path.join(directory, filename)\n",
    "            with open(file_path, 'r') as file:\n",
    "                data = json.load(file)\n",
    "            keywords_set = re.split(r'\\s*[;,]\\s*', data['keyword'])\n",
    "            keywords_count = len(keywords_set)\n",
    "            model_result_set = re.split(r'\\s*[;,]\\s*', data['model_result'])\n",
    "            model_result_count = len(model_result_set)\n",
    "            partial_matches = find_partial_matches(model_result_set, keywords_set)\n",
    "            partial_matches_count = len(partial_matches)\n",
    "            curpart = 2*partial_matches_count/(model_result_count+keywords_count)\n",
    "            if curpart < 0 or partial_matches_count<0:\n",
    "                print(filename, keywords_count, model_result_count, partial_matches_count)\n",
    "            prevsum += curpart\n",
    "    accuracy = 1/i * prevsum\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4436864936864937"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# F1\n",
    "dir = '/Users/yihanping/Documents/gatech/Research/ProcessPDF/pdf_downloads/test_dataset_large/CS/json'\n",
    "F1 =  cal_F1(dir)\n",
    "F1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
